import streamlit as st
import google.genai as genai
import requests
import json
import re
from unidecode import unidecode
from datetime import datetime

# ======================================
# CONFIG GEMINI (SDK m·ªõi)
# ======================================
# Make sure you set st.secrets["gemini_key"] in Streamlit Cloud
client = genai.Client(
    api_key=st.secrets["gemini_key"],
)

# ======================================
# DATA FILES
# ======================================
DATA_FILE = "data_tayninh.txt"
IMAGES_FILE = "images.json"

# Load d·ªØ li·ªáu ·∫£nh
try:
    with open(IMAGES_FILE, "r", encoding="utf-8") as f:
        images = json.load(f)
except Exception:
    images = {}
    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y images.json ho·∫∑c JSON kh√¥ng h·ª£p l·ªá")

# Load d·ªØ li·ªáu du l·ªãch
try:
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()
except Exception:
    raw_text = ""
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y file data_tayninh.txt")

# Chia d·ªØ li·ªáu theo ƒë·ªãa ƒëi·ªÉm (### T√™n ƒë·ªãa ƒëi·ªÉm)
tourism_data = {}
current_key = None
for line in raw_text.splitlines():
    line = line.strip()
    if line.startswith("###"):
        place = line.replace("###", "").strip()
        tourism_data[place] = ""
        current_key = place
    elif current_key:
        tourism_data[current_key] += line + "\n"

# ======================================
# UTIL FUNCTIONS
# ======================================
def normalize(text):
    if not text:
        return ""
    t = unidecode(text.lower())
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

def is_new_question(user_msg, last_bot_msg):
    if not last_bot_msg:
        return True
    nm = normalize(user_msg)
    if len(nm.split()) <= 3:
        return False
    if any(x in nm for x in ["tai sao", "o dau", "gio mo cua", "la gi", "du lich", "bao nhieu"]):
        return True
    return False

@st.cache_data(ttl=300)
def get_weather_simple(lat, lon):
    url = (
        f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
        "&current_weather=true&hourly=precipitation_probability&timezone=auto"
    )
    try:
        res = requests.get(url, timeout=10)
        return res.json()
    except Exception:
        return None

def clean_rag_data(text):
    if not text: return ""
    # 1. X√≥a c√°c ƒë∆∞·ªùng link http/https
    text = re.sub(r'http\S+', '', text)
    # 2. X√≥a ch·ªØ "Link Google Maps:" th·ª´a ra
    text = text.replace("Link Google Maps:", "")
    # 3. X√≥a kho·∫£ng tr·∫Øng th·ª´a
    return text.strip()
    
# ======================================
# STREAMLIT UI
# ======================================
st.set_page_config(page_title="Chatbot Du L·ªãch T√¢y Ninh", page_icon="üó∫Ô∏è")
st.title("üó∫Ô∏è Chatbot Du L·ªãch T√¢y Ninh ‚Äì Gemini Streaming")
st.caption("Made by ƒêƒÉng Khoa üî∞ - 1.1")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_bot" not in st.session_state:
    st.session_state.last_bot = ""

# Show conversation
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi...")

if user_input:
    # 1. Hi·ªÉn th·ªã tin nh·∫Øn User
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. X·ª≠ l√Ω RAG v√† Prompt
    related_data = ""
    user_norm = normalize(user_input)
    
    # T√¨m d·ªØ li·ªáu li√™n quan
    for place in tourism_data:
        place_norm = normalize(place)
        if place_norm in user_norm:
            raw_data = tourism_data[place]
            related_data = clean_rag_data(raw_data)
            if len(related_data) > 3000:
                related_data = related_data[:3000] + "..."
            break

    # C·∫•u h√¨nh Prompt
    lh = "B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch T√¢y Ninh am hi·ªÉu. Tr·∫£ l·ªùi ti·∫øng Vi·ªát, tr√¨nh b√†y ƒë·∫πp, ng·∫Øn g·ªçn."

    if related_data:
        prompt_user = f"""{lh}
        D·ª±a v√†o th√¥ng tin sau ƒë·ªÉ tr·∫£ l·ªùi (kh√¥ng b·ªãa ƒë·∫∑t):
        --- D·ªÆ LI·ªÜU ---
        {related_data}
        ---------------
        C√¢u h·ªèi: {user_input}
        """
    else:
        # Prompt "m·ªü" h∆°n cho c√°c c√¢u ch√†o h·ªèi x√£ giao
        prompt_user = f"""{lh}
        C√¢u h·ªèi: {user_input}
        (N·∫øu l√† ch√†o h·ªèi, h√£y ch√†o l·∫°i th√¢n thi·ªán. N·∫øu h·ªèi v·ªÅ T√¢y Ninh m√† kh√¥ng c√≥ d·ªØ li·ªáu, h√£y d√πng ki·∫øn th·ª©c chung).
        """

    # 3. G·ªçi Gemini API (Logic l·∫•y text si√™u b·ªÅn v·ªØng)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_text = ""
        gemini_config = {"max_output_tokens": 512} 

        try:
            # --- G·ªåI STREAMING ---
            stream = client.models.generate_content_stream(
                model="gemini-2.5-flash", 
                contents=prompt_user,
                config=gemini_config
            )

            for chunk in stream:
                chunk_text = ""
                # Logic l·∫•y text ƒëa t·∫ßng (Deep Extraction)
                try:
                    # ∆Øu ti√™n 1: L·∫•y tr·ª±c ti·∫øp .text
                    if hasattr(chunk, "text") and chunk.text:
                        chunk_text = chunk.text
                    # ∆Øu ti√™n 2: L·∫•y t·ª´ candidates > parts (ph√≤ng khi .text b·ªã None)
                    elif hasattr(chunk, "candidates") and chunk.candidates:
                        parts = chunk.candidates[0].content.parts
                        chunk_text = "".join([p.text for p in parts if p.text])
                except Exception:
                    pass
                
                if chunk_text:
                    full_text += chunk_text
                    placeholder.markdown(full_text)

            # Ki·ªÉm tra cu·ªëi c√πng
            if not full_text.strip():
                raise RuntimeError("Empty Stream")

        except Exception as e_stream:
            # --- FALLBACK: G·ªåI SYNC (D·ª± ph√≤ng) ---
            try:
                resp = client.models.generate_content(
                    model="gemini-2.5-flash", 
                    contents=prompt_user,
                    config=gemini_config
                )
                
                # Logic l·∫•y text cho Sync (Deep Extraction)
                full_text = ""
                
                if hasattr(resp, "text") and resp.text:
                    full_text = resp.text
                elif hasattr(resp, "candidates") and resp.candidates:
                    try:
                        candidate = resp.candidates[0]
                        # Ki·ªÉm tra candidate v√† content c√≥ t·ªìn t·∫°i kh√¥ng
                        if hasattr(candidate, "content") and candidate.content:
                            parts = getattr(candidate.content, "parts", None) # L·∫•y parts an to√†n
                            
                            # Ch·ªâ l·∫∑p n·∫øu parts t·ªìn t·∫°i v√† l√† list
                            if parts and isinstance(parts, list):
                                full_text = "".join([p.text for p in parts if hasattr(p, 'text') and p.text])
                            else:
                                # N·∫øu kh√¥ng c√≥ parts (th∆∞·ªùng do b·ªã ch·∫∑n)
                                full_text = "üö´ Ph·∫£n h·ªìi b·ªã ch·∫∑n n·ªôi dung c·∫•p th·∫•p."
                    except Exception as e_candidate:
                             # L·ªói kh√°c khi truy c·∫≠p candidates
                        full_text = f"üö´ L·ªói truy c·∫≠p ph·∫£n h·ªìi: {e_candidate}"
    
                if not full_text or full_text.startswith("üö´"):
                            # N·∫øu v·∫´n r·ªóng, ki·ªÉm tra l·∫°i l·ªói ch·∫∑n c·∫•p cao
                    if hasattr(resp, "prompt_feedback") and resp.prompt_feedback.block_reason:
                        reason = resp.prompt_feedback.block_reason.name
                        full_text = f"üö´ B·ªä CH·∫∂N: Ph·∫£n h·ªìi vi ph·∫°m ch√≠nh s√°ch an to√†n ({reason})."
                    elif full_text == "":
                         full_text = "‚ö†Ô∏è Gemini kh√¥ng ph·∫£n h·ªìi (Ph·∫£n h·ªìi r·ªóng ho√†n to√†n)."

                 placeholder.markdown(full_text)

            except Exception as e_sync:
                st.error("‚ùå L·ªói k·∫øt n·ªëi:")
                st.code(f"Stream Error: {e_stream}\nSync Error: {e_sync}")
                st.stop()
        
        # 4. L∆∞u l·ªãch s·ª≠
        st.session_state.messages.append({"role": "assistant", "content": full_text})
        st.session_state.last_bot = full_text

    # 5. Hi·ªÉn th·ªã ·∫£nh (n·∫øu c√≥ keyword ƒë·ªãa ƒëi·ªÉm trong c√¢u h·ªèi)
    # Logic: Ch·ªâ hi·ªán ·∫£nh n·∫øu t√¨m th·∫•y key trong tourism_data tr√πng v·ªõi c√¢u h·ªèi
    found_img = False
    for place in tourism_data.keys():
        if normalize(place) in normalize(user_input):
            if place in images and isinstance(images[place], list):
                if not found_img: 
                    st.divider()
                    st.caption(f"üì∏ H√¨nh ·∫£nh g·ª£i √Ω: {place}")
                    found_img = True
                cols = st.columns(min(len(images[place]), 3))
                for idx, col in enumerate(cols):
                    col.image(images[place][idx], use_container_width=True)
            break # Ch·ªâ hi·ªán ·∫£nh c·ªßa 1 ƒë·ªãa ƒëi·ªÉm ch√≠nh nh·∫•t

    # 6. Hi·ªÉn th·ªã th·ªùi ti·∫øt
    st.divider()
    cols_weather = st.columns(2)
    lat, lon = 10.5359, 106.4137
    weather = get_weather_simple(lat, lon)
    
    if weather:
        current = weather.get("current_weather", {})
        temp = current.get("temperature", "--")
        with cols_weather[0]:
            st.info(f"üå§Ô∏è Nhi·ªát ƒë·ªô T√¢y Ninh: **{temp}¬∞C**")











