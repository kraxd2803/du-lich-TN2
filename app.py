import streamlit as st
import google.genai as genai
import requests
import json
import re
from unidecode import unidecode
from datetime import datetime

# ======================================
# CONFIG GEMINI (SDK m·ªõi)
# ======================================
# Make sure you set st.secrets["gemini_key"] in Streamlit Cloud
client = genai.Client(
    api_key=st.secrets["gemini_key"],
)

# ======================================
# DATA FILES
# ======================================
DATA_FILE = "data_tayninh.txt"
IMAGES_FILE = "images.json"

# Load d·ªØ li·ªáu ·∫£nh
try:
    with open(IMAGES_FILE, "r", encoding="utf-8") as f:
        images = json.load(f)
except Exception:
    images = {}
    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y images.json ho·∫∑c JSON kh√¥ng h·ª£p l·ªá")

# Load d·ªØ li·ªáu du l·ªãch
try:
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()
except Exception:
    raw_text = ""
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y file data_tayninh.txt")

# Chia d·ªØ li·ªáu theo ƒë·ªãa ƒëi·ªÉm (### T√™n ƒë·ªãa ƒëi·ªÉm)
tourism_data = {}
current_key = None
for line in raw_text.splitlines():
    line = line.strip()
    if line.startswith("###"):
        place = line.replace("###", "").strip()
        tourism_data[place] = ""
        current_key = place
    elif current_key:
        tourism_data[current_key] += line + "\n"

# ======================================
# UTIL FUNCTIONS
# ======================================
def normalize(text):
    if not text:
        return ""
    t = unidecode(text.lower())
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

def is_new_question(user_msg, last_bot_msg):
    if not last_bot_msg:
        return True
    nm = normalize(user_msg)
    if len(nm.split()) <= 3:
        return False
    if any(x in nm for x in ["tai sao", "o dau", "gio mo cua", "la gi", "du lich", "bao nhieu"]):
        return True
    return False

@st.cache_data(ttl=300)
def get_weather_simple(lat, lon):
    url = (
        f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
        "&current_weather=true&hourly=precipitation_probability&timezone=auto"
    )
    try:
        res = requests.get(url, timeout=10)
        return res.json()
    except Exception:
        return None

# ======================================
# STREAMLIT UI
# ======================================
st.set_page_config(page_title="Chatbot Du L·ªãch T√¢y Ninh", page_icon="üó∫Ô∏è")
st.title("üó∫Ô∏è Chatbot Du L·ªãch T√¢y Ninh ‚Äì Gemini Streaming")
st.caption("Made by ƒêƒÉng Khoa üî∞ - 1.1")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_bot" not in st.session_state:
    st.session_state.last_bot = ""

# Show conversation
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi...")

if user_input:
    # 1. Hi·ªÉn th·ªã tin nh·∫Øn User
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. T√¨m d·ªØ li·ªáu li√™n quan (RAG)
    related_data = ""
    for place in tourism_data:
        if place.lower() in user_input.lower():
            related_data = tourism_data[place]
            break
    if related_data == "":
        related_data = "Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu tr·ª±c ti·∫øp trong kho d·ªØ li·ªáu."

    # 3. T·∫°o Prompt
    new_question = is_new_question(user_input, st.session_state.last_bot)
    if new_question:
        lh = "B·∫°n l√† chatbot du l·ªãch t·ªânh T√¢y Ninh. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, ch√≠nh x√°c, ti·∫øng Vi·ªát."
        # T·∫°m th·ªùi b·ªè D·ªØ li·ªáu tham kh·∫£o ƒë·ªÉ ki·ªÉm tra l·ªói an to√†n
        prompt_user = f"{lh}\n\nC√¢u h·ªèi:\n{user_input}\n\nD·ªØ li·ªáu tham kh·∫£o:\n{related_data}\n"
    else:
        # T·∫°m th·ªùi b·ªè D·ªØ li·ªáu tham kh·∫£o
        prompt_user = f"Ti·∫øp t·ª•c cu·ªôc tr√≤ chuy·ªán. Tin nh·∫Øn user: {user_input}\n\nD·ªØ li·ªáu tham kh·∫£o:\n{related_data}\n"
        # D·ªØ li·ªáu tham kh·∫£o:\n{related_data}\n" # Gi·ªØ nguy√™n d√≤ng n√†y ƒë·ªÉ tham kh·∫£o
    
    # 4. G·ªçi Gemini API (S·ª≠a l·ªói 'NoneType' v√† th√™m config token)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_text = ""
        
        # C·∫•u h√¨nh Token Output (256 tokens)
        gemini_config = {"max_output_tokens": 256} 

        # --- B·∫ÆT ƒê·∫¶U G·ªåI API ---
        try:
            # A. Th·ª≠ Streaming
            stream = client.models.generate_content_stream(
                model="gemini-2.5-flash", 
                contents=prompt_user,
                config=gemini_config # Th√™m gi·ªõi h·∫°n token
            )

            for chunk in stream:
                chunk_text = ""
                # L·∫•y text t·ª´ chunk (c·∫•u tr√∫c m·ªõi)
                try:
                    if hasattr(chunk, "text") and chunk.text:
                        chunk_text = chunk.text
                except Exception:
                    pass
                
                if chunk_text:
                    full_text += chunk_text
                    placeholder.markdown(full_text)

            # N·∫øu full_text r·ªóng sau khi streaming xong, ki·ªÉm tra l·ªói v√† raise
            if not full_text.strip():
                # D√πng l·ªói t√πy ch·ªânh ƒë·ªÉ d·ªÖ debug h∆°n
                raise RuntimeError("Ph·∫£n h·ªìi r·ªóng (C√≥ th·ªÉ b·ªã l·ªçc n·ªôi dung).") 

        except Exception as e_stream:
            # B. N·∫øu Stream l·ªói -> Fallback sang g·ªçi Sync
            try:
                resp = client.models.generate_content(
                    model="gemini-2.5-flash", 
                    contents=prompt_user,
                    config=gemini_config # Th√™m gi·ªõi h·∫°n token
                )
                
                # --- LOGIC X·ª¨ L√ù PH·∫¢N H·ªíI R·∫ÆN CH·∫ÆC H∆†N (ƒê√É S·ª¨A L·ªñI AttributeError) ---
               # --- LOGIC X·ª¨ L√ù PH·∫¢N H·ªíI R·∫ÆN CH·∫ÆC H∆†N ---
                full_text = ""
            
            # 1. KI·ªÇM TRA L·ªñI L·ªåC AN TO√ÄN TR∆Ø·ªöC
                if (hasattr(resp, "prompt_feedback") and resp.prompt_feedback is not None and 
                    hasattr(resp.prompt_feedback, "block_reason") and resp.prompt_feedback.block_reason):
                
                    reason_name = resp.prompt_feedback.block_reason.name if hasattr(resp.prompt_feedback.block_reason, 'name') else 'L√Ω do kh√¥ng x√°c ƒë·ªãnh'
                    full_text = f"üö´ N·ªôi dung b·ªã ch·∫∑n do vi ph·∫°m ch√≠nh s√°ch an to√†n: **{reason_name}**"
            
            # 2. KI·ªÇM TRA XEM C√ì TEXT TR·∫¢ V·ªÄ KH√îNG
                elif hasattr(resp, "text") and resp.text:
                    full_text = resp.text
            
            # 3. Ph√¢n t√≠ch c·∫•u tr√∫c s√¢u h∆°n (d√†nh cho c√°c tr∆∞·ªùng h·ª£p hi·∫øm g·∫∑p)
                elif hasattr(resp, "candidates") and resp.candidates:
                    cand = resp.candidates[0]
                    if hasattr(cand, "content") and cand.content:
                        parts = getattr(cand.content, "parts", None)
                        if parts:
                            full_text = "".join([p.text for p in parts if hasattr(p, 'text') and p.text])
            
            # 4. N·∫øu v·∫´n kh√¥ng c√≥ n·ªôi dung, b√°o l·ªói chung chung (Gi·ªØ nguy√™n d√≤ng n√†y)
                if not full_text:
                     full_text = "‚ö†Ô∏è Ph·∫£n h·ªìi r·ªóng ho·∫∑c kh√¥ng c√≥ n·ªôi dung li√™n quan."

                placeholder.markdown(full_text)

            except Exception as e_sync:
                # C. C·∫£ 2 ƒë·ªÅu l·ªói -> In l·ªói chi ti·∫øt
                st.error("‚ùå ƒê√£ x·∫£y ra l·ªói k·∫øt n·ªëi Gemini:")
                st.write("L·ªói Stream:", e_stream)
                st.write("L·ªói Sync:", e_sync)
                st.stop()
        
        # --- K·∫æT TH√öC G·ªåI API ---

        # 5. L∆∞u l·ªãch s·ª≠
        st.session_state.messages.append({"role": "assistant", "content": full_text})
        st.session_state.last_bot = full_text
        
    # 6. Hi·ªÉn th·ªã ·∫£nh li√™n quan (n·∫øu c√≥)
    found_img = False
    for place in tourism_data.keys():
        if place.lower() in user_input.lower() and place in images and isinstance(images[place], list):
            if not found_img: 
                st.subheader(f"üì∏ H√¨nh ·∫£nh g·ª£i √Ω:")
                found_img = True
            st.caption(f"üìç {place}")
            # Hi·ªÉn th·ªã t·ªëi ƒëa 3 ·∫£nh ƒë·ªÉ kh√¥ng qu√° d√†i
            cols = st.columns(min(len(images[place]), 3))
            for idx, col in enumerate(cols):
                col.image(images[place][idx], use_container_width=True)

    # 7. Hi·ªÉn th·ªã th·ªùi ti·∫øt
    st.divider()
    cols_weather = st.columns(2)
    lat, lon = 10.5359, 106.4137 # T·ªça ƒë·ªô T√¢y Ninh
    weather = get_weather_simple(lat, lon)
    
    if weather:
        current = weather.get("current_weather", {})
        temp = current.get("temperature", "--")
        
        with cols_weather[0]:
            st.info(f"üå§Ô∏è Nhi·ªát ƒë·ªô T√¢y Ninh: **{temp}¬∞C**")
















