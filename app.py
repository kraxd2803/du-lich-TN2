import streamlit as st
import google.genai as genai
import requests
import json
import re
from unidecode import unidecode
from datetime import datetime

# ======================================
# CONFIG GEMINI (SDK m·ªõi)
# ======================================
# Make sure you set st.secrets["gemini_key"] in Streamlit Cloud
client = genai.Client(
    api_key=st.secrets["gemini_key"],
)

# ======================================
# DATA FILES
# ======================================
DATA_FILE = "data_tayninh.txt"
IMAGES_FILE = "images.json"

# Load d·ªØ li·ªáu ·∫£nh
try:
    with open(IMAGES_FILE, "r", encoding="utf-8") as f:
        images = json.load(f)
except Exception:
    images = {}
    st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y images.json ho·∫∑c JSON kh√¥ng h·ª£p l·ªá")

# Load d·ªØ li·ªáu du l·ªãch
try:
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()
except Exception:
    raw_text = ""
    st.error("‚ùå Kh√¥ng t√¨m th·∫•y file data_tayninh.txt")

# Chia d·ªØ li·ªáu theo ƒë·ªãa ƒëi·ªÉm (### T√™n ƒë·ªãa ƒëi·ªÉm)
tourism_data = {}
current_key = None
for line in raw_text.splitlines():
    line = line.strip()
    if line.startswith("###"):
        place = line.replace("###", "").strip()
        tourism_data[place] = ""
        current_key = place
    elif current_key:
        tourism_data[current_key] += line + "\n"

# ======================================
# UTIL FUNCTIONS
# ======================================
def normalize(text):
    if not text:
        return ""
    t = unidecode(text.lower())
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

def is_new_question(user_msg, last_bot_msg):
    if not last_bot_msg:
        return True
    nm = normalize(user_msg)
    if len(nm.split()) <= 3:
        return False
    if any(x in nm for x in ["tai sao", "o dau", "gio mo cua", "la gi", "du lich", "bao nhieu"]):
        return True
    return False

@st.cache_data(ttl=300)
def get_weather_simple(lat, lon):
    url = (
        f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
        "&current_weather=true&hourly=precipitation_probability&timezone=auto"
    )
    try:
        res = requests.get(url, timeout=10)
        return res.json()
    except Exception:
        return None

def clean_rag_data(text):
    if not text: return ""
    # 1. X√≥a c√°c ƒë∆∞·ªùng link http/https
    text = re.sub(r'http\S+', '', text)
    # 2. X√≥a ch·ªØ "Link Google Maps:" th·ª´a ra
    text = text.replace("Link Google Maps:", "")
    # 3. X√≥a kho·∫£ng tr·∫Øng th·ª´a
    return text.strip()
    
# ======================================
# STREAMLIT UI
# ======================================
st.set_page_config(page_title="Chatbot Du L·ªãch T√¢y Ninh", page_icon="üó∫Ô∏è")
st.title("üó∫Ô∏è Chatbot Du L·ªãch T√¢y Ninh ‚Äì Gemini Streaming")
st.caption("Made by ƒêƒÉng Khoa üî∞ - 1.1")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_bot" not in st.session_state:
    st.session_state.last_bot = ""

# Show conversation
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nh·∫≠p c√¢u h·ªèi...")

if user_input:
    # 1. Hi·ªÉn th·ªã tin nh·∫Øn User
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    related_data = ""
    # Chu·∫©n h√≥a input ng∆∞·ªùi d√πng ƒë·ªÉ so s√°nh (b·ªè d·∫•u, vi·∫øt th∆∞·ªùng)
    user_norm = normalize(user_input)
    
    for place in tourism_data:
        # Chu·∫©n h√≥a t√™n ƒë·ªãa ƒëi·ªÉm trong data (v√≠ d·ª•: "n√∫i b√† ƒëen" -> "nui ba den")
        place_norm = normalize(place)
        
        # Ki·ªÉm tra xem t·ª´ kh√≥a ƒë·ªãa ƒëi·ªÉm c√≥ n·∫±m trong c√¢u h·ªèi kh√¥ng
        if place_norm in user_norm:
            raw_data = tourism_data[place]
            # QUAN TR·ªåNG: L√†m s·∫°ch d·ªØ li·ªáu (x√≥a link Maps) tr∆∞·ªõc khi d√πng
            related_data = clean_rag_data(raw_data)
            
            # C·∫Øt ng·∫Øn n·∫øu qu√° d√†i (tr√°nh t·ªën token)
            if len(related_data) > 3000:
                related_data = related_data[:3000] + "..."
            
            # ƒê√£ t√¨m th·∫•y th√¨ d·ª´ng l·∫°i, kh√¥ng t√¨m ti·∫øp
            break
            
    lh = "B·∫°n l√† h∆∞·ªõng d·∫´n vi√™n du l·ªãch T√¢y Ninh am hi·ªÉu. Tr·∫£ l·ªùi ti·∫øng Vi·ªát, tr√¨nh b√†y ƒë·∫πp, ng·∫Øn g·ªçn."

    if related_data:
        # TR∆Ø·ªúNG H·ª¢P A: C√ì D·ªÆ LI·ªÜU THAM KH·∫¢O (ƒê√£ l·ªçc s·∫°ch)
        prompt_user = f"""{lh}
        
        H√£y tr·∫£ l·ªùi c√¢u h·ªèi ph·∫ßn l·ªõn d·ª±a tr√™n th√¥ng tin d∆∞·ªõi ƒë√¢y. 
        C√≥ th·ªÉ k·∫øt h·ª£p th√¥ng tin c·ªßa b·∫°n nh∆∞ng tuy·ªát ƒë·ªëi kh√¥ng b·ªãa ƒë·∫∑t th√¥ng tin n·∫øu kh√¥ng ch·∫Øc ch·∫Øn ch√≠nh x√°c.
        
        --- D·ªÆ LI·ªÜU V·ªÄ {place.upper()} ---
        {related_data}
        ----------------------------------
        
        C√¢u h·ªèi: {user_input}
        """
        # (T√πy ch·ªçn) Hi·ªÉn th·ªã th√¥ng b√°o nh·ªè ƒë·ªÉ bi·∫øt bot ƒëang ƒë·ªçc data
        # st.toast(f"ƒêang ƒë·ªçc d·ªØ li·ªáu v·ªÅ: {place}") 
        
    else:
        # TR∆Ø·ªúNG H·ª¢P B: KH√îNG T√åM TH·∫§Y D·ªÆ LI·ªÜU C·ª§ TH·ªÇ
        # Cho ph√©p ch√©m gi√≥ d·ª±a tr√™n ki·∫øn th·ª©c chung, nh∆∞ng nh·∫Øc kh√©o
        prompt_user = f"""{lh}
        
        C√¢u h·ªèi: {user_input}
        (H√£y tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c chung c·ªßa b·∫°n v·ªÅ T√¢y Ninh).
        """

    # 4. G·ªçi Gemini API (S·ª≠a l·ªói Indentation v√† Logic)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_text = ""
        
        # C·∫•u h√¨nh Token Output (256 tokens)
        gemini_config = {"max_output_tokens": 256} 

        # --- B·∫ÆT ƒê·∫¶U G·ªåI API ---
        try:
            # A. Th·ª≠ Streaming
            stream = client.models.generate_content_stream(
                model="gemini-2.5-flash", 
                contents=prompt_user,
                config=gemini_config
            )

            for chunk in stream:
                chunk_text = ""
                try:
                    if hasattr(chunk, "text") and chunk.text:
                        chunk_text = chunk.text
                except Exception:
                    pass
                
                if chunk_text:
                    full_text += chunk_text
                    placeholder.markdown(full_text)

            if not full_text.strip():
                raise RuntimeError("Ph·∫£n h·ªìi r·ªóng (C√≥ th·ªÉ b·ªã l·ªçc n·ªôi dung).") 

        except Exception as e_stream:
            # B. N·∫øu Stream l·ªói -> Fallback sang g·ªçi Sync
            try:
                resp = client.models.generate_content(
                    model="gemini-2.5-flash", 
                    contents=prompt_user,
                    config=gemini_config
                )
                
                # --- LOGIC X·ª¨ L√ù PH·∫¢N H·ªíI R·∫ÆN CH·∫ÆC H∆†N (ƒê√É S·ª¨A L·ªñI TH·ª§T L·ªÄ) ---
                full_text = ""
                
                # 1. KI·ªÇM TRA L·ªñI L·ªåC AN TO√ÄN TR∆Ø·ªöC
                if (hasattr(resp, "prompt_feedback") and resp.prompt_feedback is not None and 
                    hasattr(resp.prompt_feedback, "block_reason") and resp.prompt_feedback.block_reason):
                    
                    reason_name = resp.prompt_feedback.block_reason.name if hasattr(resp.prompt_feedback.block_reason, 'name') else 'L√Ω do kh√¥ng x√°c ƒë·ªãnh'
                    full_text = f"üö´ N·ªôi dung b·ªã ch·∫∑n do vi ph·∫°m ch√≠nh s√°ch an to√†n: **{reason_name}**"
                
                # 2. KI·ªÇM TRA XEM C√ì TEXT TR·∫¢ V·ªÄ KH√îNG
                elif hasattr(resp, "text") and resp.text:
                    full_text = resp.text
                
                # 3. N·∫øu v·∫´n kh√¥ng c√≥ n·ªôi dung
                if not full_text:
                     full_text = "‚ö†Ô∏è Ph·∫£n h·ªìi r·ªóng ho·∫∑c kh√¥ng c√≥ n·ªôi dung li√™n quan."

                placeholder.markdown(full_text)

            except Exception as e_sync:
                # C. C·∫£ 2 ƒë·ªÅu l·ªói -> In l·ªói chi ti·∫øt
                st.error("‚ùå ƒê√£ x·∫£y ra l·ªói k·∫øt n·ªëi Gemini:")
                st.write("L·ªói Stream:", e_stream)
                st.write("L·ªói Sync:", e_sync)
                st.stop()
        
        # --- K·∫æT TH√öC G·ªåI API ---

        # 5. L∆∞u l·ªãch s·ª≠
        st.session_state.messages.append({"role": "assistant", "content": full_text})
        st.session_state.last_bot = full_text
        
        # 6. Hi·ªÉn th·ªã ·∫£nh li√™n quan (ƒê√£ lo·∫°i b·ªè logic RAG ph·ª©c t·∫°p, ch·ªâ gi·ªØ l·∫°i hi·ªÉn th·ªã)
        # B·∫†N C·∫¶N TH√äM L·∫†I LOGIC T√åM KI·∫æM PLACE T·∫†I ƒê√ÇY N·∫æU MU·ªêN HI·ªÇN TH·ªä ·∫¢NH
        
    # 7. Hi·ªÉn th·ªã th·ªùi ti·∫øt (ƒê√£ s·ª≠a l·ªói th·ª•t l·ªÅ)
    st.divider()
    cols_weather = st.columns(2)
    lat, lon = 10.5359, 106.4137 # T·ªça ƒë·ªô T√¢y Ninh
    weather = get_weather_simple(lat, lon)
    
    if weather:
        current = weather.get("current_weather", {})
        temp = current.get("temperature", "--")
        
        with cols_weather[0]:
            st.info(f"üå§Ô∏è Nhi·ªát ƒë·ªô T√¢y Ninh: **{temp}¬∞C**")




















