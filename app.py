import streamlit as st
import google.genai as genai
import requests
import json
import re
from unidecode import unidecode
from datetime import datetime

# ======================================
# CONFIG GEMINI (SDK má»›i)
# ======================================
# Make sure you set st.secrets["gemini_key"] in Streamlit Cloud
client = genai.Client(
    api_key=st.secrets["gemini_key"],
)

# ======================================
# DATA FILES
# ======================================
DATA_FILE = "data_tayninh.txt"
IMAGES_FILE = "images.json"

# Load dá»¯ liá»‡u áº£nh
try:
    with open(IMAGES_FILE, "r", encoding="utf-8") as f:
        images = json.load(f)
except Exception:
    images = {}
    st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y images.json hoáº·c JSON khÃ´ng há»£p lá»‡")

# Load dá»¯ liá»‡u du lá»‹ch
try:
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()
except Exception:
    raw_text = ""
    st.error("âŒ KhÃ´ng tÃ¬m tháº¥y file data_tayninh.txt")

# Chia dá»¯ liá»‡u theo Ä‘á»‹a Ä‘iá»ƒm (### TÃªn Ä‘á»‹a Ä‘iá»ƒm)
tourism_data = {}
current_key = None
for line in raw_text.splitlines():
    line = line.strip()
    if line.startswith("###"):
        place = line.replace("###", "").strip()
        tourism_data[place] = ""
        current_key = place
    elif current_key:
        tourism_data[current_key] += line + "\n"

# ======================================
# UTIL FUNCTIONS
# ======================================
def normalize(text):
    if not text:
        return ""
    t = unidecode(text.lower())
    t = re.sub(r"[^a-z0-9\s]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

def is_new_question(user_msg, last_bot_msg):
    if not last_bot_msg:
        return True
    nm = normalize(user_msg)
    if len(nm.split()) <= 3:
        return False
    if any(x in nm for x in ["tai sao", "o dau", "gio mo cua", "la gi", "du lich", "bao nhieu"]):
        return True
    return False

@st.cache_data(ttl=300)
def get_weather_simple(lat, lon):
    url = (
        f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}"
        "&current_weather=true&hourly=precipitation_probability&timezone=auto"
    )
    try:
        res = requests.get(url, timeout=10)
        return res.json()
    except Exception:
        return None

def clean_rag_data(text):
    if not text: return ""
    # 1. XÃ³a cÃ¡c Ä‘Æ°á»ng link http/https
    text = re.sub(r'http\S+', '', text)
    # 2. XÃ³a chá»¯ "Link Google Maps:" thá»«a ra
    text = text.replace("Link Google Maps:", "")
    # 3. XÃ³a khoáº£ng tráº¯ng thá»«a
    return text.strip()
    
# ======================================
# STREAMLIT UI
# ======================================
st.set_page_config(page_title="Chatbot Du Lá»‹ch TÃ¢y Ninh", page_icon="ğŸ—ºï¸")
st.title("ğŸ—ºï¸ Chatbot Du Lá»‹ch TÃ¢y Ninh â€“ Gemini Streaming")
st.caption("Made by ÄÄƒng Khoa ğŸ”° - 1.1")

if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_bot" not in st.session_state:
    st.session_state.last_bot = ""

# Show conversation
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_input = st.chat_input("Nháº­p cÃ¢u há»i...")

if user_input:
    # 1. Hiá»ƒn thá»‹ tin nháº¯n User
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # 2. Xá»­ lÃ½ RAG vÃ  Prompt
    related_data = ""
    user_norm = normalize(user_input)
    
    # TÃ¬m dá»¯ liá»‡u liÃªn quan
    for place in tourism_data:
        place_norm = normalize(place)
        if place_norm in user_norm:
            raw_data = tourism_data[place]
            related_data = clean_rag_data(raw_data)
            if len(related_data) > 3000:
                related_data = related_data[:3000] + "..."
            break

    # Cáº¥u hÃ¬nh Prompt
    lh = "Báº¡n lÃ  hÆ°á»›ng dáº«n viÃªn du lá»‹ch TÃ¢y Ninh am hiá»ƒu. Tráº£ lá»i tiáº¿ng Viá»‡t, trÃ¬nh bÃ y Ä‘áº¹p, ngáº¯n gá»n."

    if related_data:
        prompt_user = f"""{lh}
        Dá»±a vÃ o thÃ´ng tin sau Ä‘á»ƒ tráº£ lá»i (khÃ´ng bá»‹a Ä‘áº·t):
        --- Dá»® LIá»†U ---
        {related_data}
        ---------------
        CÃ¢u há»i: {user_input}
        """
    else:
        # Prompt "má»Ÿ" hÆ¡n cho cÃ¡c cÃ¢u chÃ o há»i xÃ£ giao
        prompt_user = f"""{lh}
        CÃ¢u há»i: {user_input}
        (Náº¿u lÃ  chÃ o há»i, hÃ£y chÃ o láº¡i thÃ¢n thiá»‡n. Náº¿u há»i vá» TÃ¢y Ninh mÃ  khÃ´ng cÃ³ dá»¯ liá»‡u, hÃ£y dÃ¹ng kiáº¿n thá»©c chung).
        """

    # 3. Gá»i Gemini API (Logic láº¥y text siÃªu bá»n vá»¯ng)
    with st.chat_message("assistant"):
        placeholder = st.empty()
        full_text = ""
        gemini_config = {"max_output_tokens": 512} 

        try:
            # --- Gá»ŒI STREAMING ---
            stream = client.models.generate_content_stream(
                model="gemini-2.5-flash", 
                contents=prompt_user,
                config=gemini_config
            )

            for chunk in stream:
                chunk_text = ""
                # Logic láº¥y text Ä‘a táº§ng (Deep Extraction)
                try:
                    # Æ¯u tiÃªn 1: Láº¥y trá»±c tiáº¿p .text
                    if hasattr(chunk, "text") and chunk.text:
                        chunk_text = chunk.text
                    # Æ¯u tiÃªn 2: Láº¥y tá»« candidates > parts (phÃ²ng khi .text bá»‹ None)
                    elif hasattr(chunk, "candidates") and chunk.candidates:
                        parts = chunk.candidates[0].content.parts
                        chunk_text = "".join([p.text for p in parts if p.text])
                except Exception:
                    pass
                
                if chunk_text:
                    full_text += chunk_text
                    placeholder.markdown(full_text)

            # Kiá»ƒm tra cuá»‘i cÃ¹ng
            if not full_text.strip():
                raise RuntimeError("Empty Stream")

        except Exception as e_stream:
            # --- FALLBACK: Gá»ŒI SYNC (Dá»± phÃ²ng) ---
            try:
                resp = client.models.generate_content(
                    model="gemini-2.5-flash", 
                    contents=prompt_user,
                    config=gemini_config
                )
                
                # Logic láº¥y text cho Sync (Deep Extraction)
                full_text = ""
                
                if hasattr(resp, "text") and resp.text:
                    full_text = resp.text
                elif hasattr(resp, "candidates") and resp.candidates:
                    try:
                        candidate = resp.candidates[0]
                        # Kiá»ƒm tra candidate vÃ  content cÃ³ tá»“n táº¡i khÃ´ng
                        if hasattr(candidate, "content") and candidate.content:
                            parts = getattr(candidate.content, "parts", None) # Láº¥y parts an toÃ n
                            
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Chá»‰ láº·p náº¿u parts tá»“n táº¡i vÃ  lÃ  list
                            if parts and isinstance(parts, list):
                                full_text = "".join([p.text for p in parts if hasattr(p, 'text') and p.text])
                            else:
                                # Náº¿u khÃ´ng cÃ³ parts (thÆ°á»ng do bá»‹ cháº·n)
                                full_text = "ğŸš« Pháº£n há»“i bá»‹ cháº·n ná»™i dung cáº¥p tháº¥p."
                        except Exception as e_candidate:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Lá»—i khÃ¡c khi truy cáº­p candidates
                            full_text = f"ğŸš« Lá»—i truy cáº­p pháº£n há»“i: {e_candidate}"
    
                if not full_text or full_text.startswith("ğŸš«"):
                            # Náº¿u váº«n rá»—ng, kiá»ƒm tra láº¡i lá»—i cháº·n cáº¥p cao
                    if hasattr(resp, "prompt_feedback") and resp.prompt_feedback.block_reason:
                        reason = resp.prompt_feedback.block_reason.name
                        full_text = f"ğŸš« Bá»Š CHáº¶N: Pháº£n há»“i vi pháº¡m chÃ­nh sÃ¡ch an toÃ n ({reason})."
                    elif full_text == "":
                         full_text = "âš ï¸ Gemini khÃ´ng pháº£n há»“i (Pháº£n há»“i rá»—ng hoÃ n toÃ n)."

                 placeholder.markdown(full_text)

            except Exception as e_sync:
                st.error("âŒ Lá»—i káº¿t ná»‘i:")
                st.code(f"Stream Error: {e_stream}\nSync Error: {e_sync}")
                st.stop()
        
        # 4. LÆ°u lá»‹ch sá»­
        st.session_state.messages.append({"role": "assistant", "content": full_text})
        st.session_state.last_bot = full_text

    # 5. Hiá»ƒn thá»‹ áº£nh (náº¿u cÃ³ keyword Ä‘á»‹a Ä‘iá»ƒm trong cÃ¢u há»i)
    # Logic: Chá»‰ hiá»‡n áº£nh náº¿u tÃ¬m tháº¥y key trong tourism_data trÃ¹ng vá»›i cÃ¢u há»i
    found_img = False
    for place in tourism_data.keys():
        if normalize(place) in normalize(user_input):
            if place in images and isinstance(images[place], list):
                if not found_img: 
                    st.divider()
                    st.caption(f"ğŸ“¸ HÃ¬nh áº£nh gá»£i Ã½: {place}")
                    found_img = True
                cols = st.columns(min(len(images[place]), 3))
                for idx, col in enumerate(cols):
                    col.image(images[place][idx], use_container_width=True)
            break # Chá»‰ hiá»‡n áº£nh cá»§a 1 Ä‘á»‹a Ä‘iá»ƒm chÃ­nh nháº¥t

    # 6. Hiá»ƒn thá»‹ thá»i tiáº¿t
    st.divider()
    cols_weather = st.columns(2)
    lat, lon = 10.5359, 106.4137
    weather = get_weather_simple(lat, lon)
    
    if weather:
        current = weather.get("current_weather", {})
        temp = current.get("temperature", "--")
        with cols_weather[0]:
            st.info(f"ğŸŒ¤ï¸ Nhiá»‡t Ä‘á»™ TÃ¢y Ninh: **{temp}Â°C**")








